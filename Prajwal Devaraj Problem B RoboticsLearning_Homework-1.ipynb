{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6bvxzDcTLM4"
      },
      "source": [
        "## Question 2 Problem (B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLo-zoi4TmXs"
      },
      "source": [
        "### STEP 1: Manual 3×3 Convolution (from scratch) + Verification vs nn.Conv2d\n",
        "\n",
        "\n",
        "We will first implement:\n",
        "\n",
        "manual_conv2d(x, weight, bias, padding=1, stride=1)\n",
        "\n",
        "Required shapes:\n",
        "\n",
        "x: (B, Cin, H, W)\n",
        "\n",
        "weight: (Cout, Cin, 3, 3)\n",
        "\n",
        "bias: (Cout, )\n",
        "\n",
        "output y: (B, Cout, Hout, Wout)\n",
        "\n",
        "Then we will verify correctness:\n",
        "\n",
        "Create nn.Conv2d(Cin, Cout, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "\n",
        "Random input x\n",
        "\n",
        "ytorch = conv(x)\n",
        "\n",
        "Extract parameters and compute ymanual\n",
        "\n",
        "Print max_abs_diff and assert < 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT6hJNQfTKrR",
        "outputId": "aef3a3c3-71be-4567-af02-d8c6fe293360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Random Seed = 42\n",
            "max abs diff = 2.38e-07 (PASS)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Problem 2(b) - STEP 1: Manual 3x3 Conv2D + Verification\n",
        "# ==========================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def manual_conv2d(x, weight, bias=None, padding=1, stride=1):\n",
        "    \"\"\"\n",
        "    Manual 2D convolution with 3x3 kernel using clear nested loops.\n",
        "    Supports:\n",
        "      - x:      (B, Cin, H, W)\n",
        "      - weight: (Cout, Cin, 3, 3)\n",
        "      - bias:   (Cout,) or None\n",
        "      - padding=1, stride=1 (required)\n",
        "    Returns:\n",
        "      - y: (B, Cout, Hout, Wout)\n",
        "    \"\"\"\n",
        "    assert stride == 1, \"This manual implementation is required to support stride=1.\"\n",
        "    assert padding == 1, \"This manual implementation is required to support padding=1.\"\n",
        "    assert weight.shape[2:] == (3, 3), \"Kernel must be 3x3.\"\n",
        "\n",
        "    B, Cin, H, W = x.shape\n",
        "    Cout, Cin_w, Kh, Kw = weight.shape\n",
        "    assert Cin == Cin_w, \"Cin mismatch between x and weight.\"\n",
        "\n",
        "    # Pad input: (B, Cin, H+2p, W+2p)\n",
        "    x_pad = torch.nn.functional.pad(x, (padding, padding, padding, padding))  # (left,right,top,bottom)\n",
        "\n",
        "    # Output spatial dims for stride=1, padding=1, kernel=3:\n",
        "    # Hout = H, Wout = W\n",
        "    Hout = (H + 2*padding - Kh)//stride + 1\n",
        "    Wout = (W + 2*padding - Kw)//stride + 1\n",
        "\n",
        "    # Allocate output\n",
        "    y = torch.zeros((B, Cout, Hout, Wout), dtype=x.dtype)\n",
        "\n",
        "    # Nested loops: readability > speed\n",
        "    for b in range(B):\n",
        "        for cout in range(Cout):\n",
        "            for i in range(Hout):\n",
        "                for j in range(Wout):\n",
        "                    acc = 0.0\n",
        "                    for cin in range(Cin):\n",
        "                        for u in range(3):\n",
        "                            for v in range(3):\n",
        "                                acc += float(weight[cout, cin, u, v]) * float(x_pad[b, cin, i+u, j+v])\n",
        "                    if bias is not None:\n",
        "                        acc += float(bias[cout])\n",
        "                    y[b, cout, i, j] = acc\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Verification / Sanity Test\n",
        "# -------------------------\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "print(f\"[INFO] Random Seed = {SEED}\")\n",
        "\n",
        "# Choose small sizes for quick verification\n",
        "B, Cin, Cout, H, W = 2, 3, 4, 8, 8\n",
        "\n",
        "# Create conv layer\n",
        "conv = nn.Conv2d(Cin, Cout, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "\n",
        "# Random input\n",
        "x = torch.randn(B, Cin, H, W)\n",
        "\n",
        "# PyTorch output\n",
        "ytorch = conv(x)\n",
        "\n",
        "# Extract parameters\n",
        "w = conv.weight.detach().clone()\n",
        "b = conv.bias.detach().clone()\n",
        "\n",
        "# Manual output\n",
        "ymanual = manual_conv2d(x, w, b, padding=1, stride=1)\n",
        "\n",
        "# Compare\n",
        "max_abs_diff = (ytorch.detach() - ymanual).abs().max().item()\n",
        "print(f\"max abs diff = {max_abs_diff:.2e}\", \"(PASS)\" if max_abs_diff < 1e-5 else \"(FAIL)\")\n",
        "\n",
        "# Required assertion\n",
        "assert max_abs_diff < 1e-5, \"Manual conv does NOT match nn.Conv2d within tolerance!\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC84Vi5OT921"
      },
      "source": [
        "### STEP 2: Define CNN-Base-BN (required architecture) + shape sanity check\n",
        "\n",
        "\n",
        "Now we build the required CNN exactly:\n",
        "\n",
        "Conv(1→16, 3×3, padding=1) → BN → ReLU\n",
        "\n",
        "Conv(16→32, 3×3, padding=1) → BN → ReLU → MaxPool(2×2)\n",
        "\n",
        "Conv(32→64, 3×3, padding=1) → BN → ReLU → MaxPool(2×2)\n",
        "\n",
        "Flatten → Linear(64×7×7 → 10)\n",
        "\n",
        "We’ll also do a shape sanity check with one batch:\n",
        "\n",
        "input: (B,1,28,28)\n",
        "\n",
        "after pool1: 14×14\n",
        "\n",
        "after pool2: 7×7\n",
        "\n",
        "final logits: (B,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93C6g4hXTvrW",
        "outputId": "417ba13b-ddbf-4e3b-8e45-a7a6dace1aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Random Seed = 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 32.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.11MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.91MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Train size: 60000\n",
            "[INFO] Test size: 10000\n",
            "[SANITY] input shape: torch.Size([128, 1, 28, 28])\n",
            "[SANITY] logits shape: torch.Size([128, 10])\n",
            "[SANITY] labels shape: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Problem 2(b) - STEP 2 (Fixed): MNIST Setup + Shape Check\n",
        "# ==========================================================\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ---- Reproducibility ----\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "print(\"[INFO] Random Seed =\", SEED)\n",
        "\n",
        "# ---- Dataset ----\n",
        "transform = transforms.ToTensor()  # Normalizes to [0,1]\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"[INFO] Train size:\", len(train_ds))\n",
        "print(\"[INFO] Test size:\", len(test_ds))\n",
        "\n",
        "# ---- CNN Definition (again for safety) ----\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_Base_BN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn3   = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.fc   = nn.Linear(64*7*7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ---- Shape sanity check ----\n",
        "model = CNN_Base_BN()\n",
        "\n",
        "x_batch, y_batch = next(iter(train_loader))\n",
        "logits = model(x_batch)\n",
        "\n",
        "print(\"[SANITY] input shape:\", x_batch.shape)\n",
        "print(\"[SANITY] logits shape:\", logits.shape)\n",
        "print(\"[SANITY] labels shape:\", y_batch.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SczIofWRUXb-"
      },
      "source": [
        "### STEP 3: Train CNN-Base-BN (Cross-Entropy) with proper BatchNorm train/eval + logging\n",
        "\n",
        "\n",
        "Now we train the CNN with:\n",
        "\n",
        "Loss: nn.CrossEntropyLoss() (softmax + CE internally)\n",
        "\n",
        "Optimizer: Adam\n",
        "\n",
        "Epochs: 5\n",
        "\n",
        "Logging each epoch:\n",
        "\n",
        "train loss\n",
        "\n",
        "train accuracy\n",
        "\n",
        "test accuracy\n",
        "\n",
        "Critical requirement: using\n",
        "\n",
        "model.train() in training loop\n",
        "\n",
        "model.eval() in evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUp3gPsaUFRe",
        "outputId": "e4cf9705-9e7c-43f9-d1db-4515ff5bfb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] device: cpu\n",
            "[EPOCH 1] train_loss=0.1400 | train_acc=95.72% | test_acc=98.44% | time=123.21s\n",
            "[EPOCH 2] train_loss=0.0450 | train_acc=98.64% | test_acc=97.92% | time=129.99s\n",
            "[EPOCH 3] train_loss=0.0320 | train_acc=98.98% | test_acc=98.66% | time=129.67s\n",
            "[EPOCH 4] train_loss=0.0291 | train_acc=99.07% | test_acc=98.99% | time=128.58s\n",
            "[EPOCH 5] train_loss=0.0241 | train_acc=99.23% | test_acc=99.01% | time=132.13s\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Problem 2(b) - STEP 3: Train CNN-Base-BN with Logging\n",
        "# ==========================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"[INFO] device:\", device)\n",
        "\n",
        "model = CNN_Base_BN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "def accuracy_from_logits(logits, y):\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    start_t = time.time()\n",
        "\n",
        "    # --------------------\n",
        "    # TRAIN (BN uses batch stats)\n",
        "    # --------------------\n",
        "    model.train()\n",
        "    train_loss_sum, train_acc_sum, n_batches = 0.0, 0.0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "        train_acc_sum += accuracy_from_logits(logits, y)\n",
        "        n_batches += 1\n",
        "\n",
        "    avg_train_loss = train_loss_sum / n_batches\n",
        "    avg_train_acc = train_acc_sum / n_batches\n",
        "\n",
        "    # --------------------\n",
        "    # EVAL (BN uses running estimates)\n",
        "    # --------------------\n",
        "    model.eval()\n",
        "    test_acc_sum, test_batches = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            test_acc_sum += accuracy_from_logits(logits, y)\n",
        "            test_batches += 1\n",
        "\n",
        "    avg_test_acc = test_acc_sum / test_batches\n",
        "    epoch_time = time.time() - start_t\n",
        "\n",
        "    print(f\"[EPOCH {epoch}] train_loss={avg_train_loss:.4f} | \"\n",
        "          f\"train_acc={avg_train_acc*100:.2f}% | \"\n",
        "          f\"test_acc={avg_test_acc*100:.2f}% | \"\n",
        "          f\"time={epoch_time:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duVSrd7NUscH",
        "outputId": "0d96e351-af07-460e-de06-3dfe4988b081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Random Seed = 42\n",
            "[INFO] Train size: 60000 | Test size: 10000 | Batch size: 128\n",
            "max abs diff = 2.38e-07 (PASS)\n",
            "[SANITY] input shape: torch.Size([128, 1, 28, 28])\n",
            "[SANITY] logits shape: torch.Size([128, 10])\n",
            "[SANITY] labels shape: torch.Size([128])\n",
            "[INFO] device: cpu\n",
            "[EPOCH 1] train_loss=0.1312 | train_acc=96.04% | test_acc=98.43% | time=122.27s\n",
            "[EPOCH 2] train_loss=0.0451 | train_acc=98.54% | test_acc=98.89% | time=119.38s\n",
            "[EPOCH 3] train_loss=0.0350 | train_acc=98.90% | test_acc=98.67% | time=120.31s\n",
            "[EPOCH 4] train_loss=0.0276 | train_acc=99.10% | test_acc=98.67% | time=119.30s\n",
            "[EPOCH 5] train_loss=0.0218 | train_acc=99.28% | test_acc=98.94% | time=120.09s\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Homework 1 - Problem 2(b)\n",
        "# Manual 3x3 Convolution Verification + CNN-Base-BN Training\n",
        "# ==========================================================\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 0) Reproducibility + Data\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"[INFO] Random Seed = {SEED}\")\n",
        "\n",
        "transform = transforms.ToTensor()  # scales MNIST pixels to [0,1]\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"[INFO] Train size: {len(train_ds)} | Test size: {len(test_ds)} | Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 1) Part A: Manual 3x3 Convolution Function\n",
        "# -----------------------------------------\n",
        "def manual_conv2d(x, weight, bias=None, padding=1, stride=1):\n",
        "    \"\"\"\n",
        "    Manual 2D convolution for 3x3 kernels using explicit loops (CPU).\n",
        "    Shapes:\n",
        "      x:      (B, Cin, H, W)\n",
        "      weight: (Cout, Cin, 3, 3)\n",
        "      bias:   (Cout,) or None\n",
        "    Required: padding=1, stride=1\n",
        "    \"\"\"\n",
        "    assert stride == 1, \"Required: stride=1\"\n",
        "    assert padding == 1, \"Required: padding=1\"\n",
        "    assert weight.shape[2:] == (3, 3), \"Kernel must be 3x3\"\n",
        "\n",
        "    B, Cin, H, W = x.shape\n",
        "    Cout, Cin_w, Kh, Kw = weight.shape\n",
        "    assert Cin == Cin_w, \"Cin mismatch between x and weight\"\n",
        "\n",
        "    # Pad input: (left,right,top,bottom)\n",
        "    x_pad = F.pad(x, (padding, padding, padding, padding))\n",
        "\n",
        "    # Output dims for stride=1, padding=1, kernel=3 -> Hout=H, Wout=W\n",
        "    Hout = (H + 2 * padding - Kh) // stride + 1\n",
        "    Wout = (W + 2 * padding - Kw) // stride + 1\n",
        "\n",
        "    y = torch.zeros((B, Cout, Hout, Wout), dtype=x.dtype)\n",
        "\n",
        "    # Sliding window loops\n",
        "    for b in range(B):\n",
        "        for cout in range(Cout):\n",
        "            for i in range(Hout):\n",
        "                for j in range(Wout):\n",
        "                    acc = 0.0\n",
        "                    for cin in range(Cin):\n",
        "                        for u in range(3):\n",
        "                            for v in range(3):\n",
        "                                acc += float(weight[cout, cin, u, v]) * float(x_pad[b, cin, i + u, j + v])\n",
        "                    if bias is not None:\n",
        "                        acc += float(bias[cout])\n",
        "                    y[b, cout, i, j] = acc\n",
        "    return y\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# 2) Part A Verification vs nn.Conv2d (PASS)\n",
        "# -------------------------------------------\n",
        "B, Cin, Cout, H, W = 2, 3, 4, 8, 8\n",
        "conv = nn.Conv2d(Cin, Cout, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "\n",
        "x = torch.randn(B, Cin, H, W)\n",
        "ytorch = conv(x)\n",
        "\n",
        "w = conv.weight.detach().clone()\n",
        "b = conv.bias.detach().clone()\n",
        "\n",
        "ymanual = manual_conv2d(x, w, b, padding=1, stride=1)\n",
        "\n",
        "max_abs_diff = (ytorch.detach() - ymanual).abs().max().item()\n",
        "print(f\"max abs diff = {max_abs_diff:.2e}\", \"(PASS)\" if max_abs_diff < 1e-5 else \"(FAIL)\")\n",
        "assert max_abs_diff < 1e-5, \"Manual conv does NOT match nn.Conv2d within tolerance!\"\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# 3) Part B: CNN-Base-BN (Required Model)\n",
        "# ---------------------------------------\n",
        "class CNN_Base_BN(nn.Module):\n",
        "    \"\"\"\n",
        "    Required block pattern: Conv(3x3) -> BatchNorm2d -> ReLU\n",
        "    Architecture:\n",
        "      1) Conv(1->16, 3x3, pad=1) -> BN -> ReLU\n",
        "      2) Conv(16->32, 3x3, pad=1) -> BN -> ReLU -> MaxPool(2)\n",
        "      3) Conv(32->64, 3x3, pad=1) -> BN -> ReLU -> MaxPool(2)\n",
        "      4) Flatten -> Linear(64*7*7 -> 10)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "        self.bn3   = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc    = nn.Linear(64 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))   # 28x28\n",
        "        x = F.relu(self.bn2(self.conv2(x)))   # 28x28\n",
        "        x = self.pool(x)                      # 14x14\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))   # 14x14\n",
        "        x = self.pool(x)                      # 7x7\n",
        "\n",
        "        x = x.view(x.size(0), -1)             # 64*7*7\n",
        "        logits = self.fc(x)                   # (B,10)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Shape sanity check\n",
        "# ---------------------------\n",
        "model_tmp = CNN_Base_BN()\n",
        "xb, yb = next(iter(train_loader))\n",
        "out = model_tmp(xb)\n",
        "print(\"[SANITY] input shape:\", xb.shape)\n",
        "print(\"[SANITY] logits shape:\", out.shape)\n",
        "print(\"[SANITY] labels shape:\", yb.shape)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Train / Eval with Logging\n",
        "# ---------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"[INFO] device:\", device)\n",
        "\n",
        "model = CNN_Base_BN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "def accuracy_from_logits(logits, y):\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    start_t = time.time()\n",
        "\n",
        "    # TRAIN MODE (BN uses batch statistics)\n",
        "    model.train()\n",
        "    train_loss_sum, train_acc_sum, n_batches = 0.0, 0.0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "        train_acc_sum += accuracy_from_logits(logits, y)\n",
        "        n_batches += 1\n",
        "\n",
        "    avg_train_loss = train_loss_sum / n_batches\n",
        "    avg_train_acc = train_acc_sum / n_batches\n",
        "\n",
        "    # EVAL MODE (BN uses running mean/var)\n",
        "    model.eval()\n",
        "    test_acc_sum, test_batches = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            test_acc_sum += accuracy_from_logits(logits, y)\n",
        "            test_batches += 1\n",
        "\n",
        "    avg_test_acc = test_acc_sum / test_batches\n",
        "    epoch_time = time.time() - start_t\n",
        "\n",
        "    print(f\"[EPOCH {epoch}] train_loss={avg_train_loss:.4f} | \"\n",
        "          f\"train_acc={avg_train_acc*100:.2f}% | \"\n",
        "          f\"test_acc={avg_test_acc*100:.2f}% | \"\n",
        "          f\"time={epoch_time:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part B only (CNN-Base-BN training)\n",
        "\n",
        "MNIST loaders (normalize [0,1], batch 128, seed)\n",
        "\n",
        "CNN-Base-BN architecture (only 3×3 convs, BN after conv before ReLU)\n",
        "\n",
        "Train with nn.CrossEntropyLoss()\n",
        "\n",
        "Adam optimizer\n",
        "\n",
        "Explicit model.train() and model.eval()\n",
        "\n",
        "Log per epoch: train loss, train acc, test acc"
      ],
      "metadata": {
        "id": "qscqLq-V25oI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9r-wBCETfUhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ceb66c-78a6-4fb7-dead-9f2a56706930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Random Seed = 42\n",
            "[INFO] Train size = 60000 | Test size = 10000 | Batch size = 128\n",
            "[INFO] device: cpu\n",
            "[INFO] Optimizer=Adam | lr=1e-3 | epochs=5\n",
            "[EPOCH 1] train_loss=0.1358 | train_acc=95.87% | test_acc=98.70% | time=119.15s\n",
            "[EPOCH 2] train_loss=0.0436 | train_acc=98.64% | test_acc=98.68% | time=118.15s\n",
            "[EPOCH 3] train_loss=0.0332 | train_acc=98.95% | test_acc=98.86% | time=119.86s\n",
            "[EPOCH 4] train_loss=0.0272 | train_acc=99.12% | test_acc=99.04% | time=119.25s\n",
            "[EPOCH 5] train_loss=0.0212 | train_acc=99.32% | test_acc=98.81% | time=119.91s\n",
            "[RESULT] Final test accuracy after 5 epochs: 98.81%\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Problem 2(b) - PART B: CNN-Base-BN Training on MNIST\n",
        "# ==========================================================\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# -----------------------\n",
        "# 1) Reproducibility\n",
        "# -----------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"[INFO] Random Seed = {SEED}\")\n",
        "\n",
        "# -----------------------\n",
        "# 2) Dataset + DataLoaders\n",
        "# -----------------------\n",
        "transform = transforms.ToTensor()  # scales pixels to [0,1]\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"[INFO] Train size = {len(train_ds)} | Test size = {len(test_ds)} | Batch size = {BATCH_SIZE}\")\n",
        "\n",
        "# -----------------------\n",
        "# 3) CNN-Base-BN Model (Required)\n",
        "# -----------------------\n",
        "class CNN_Base_BN(nn.Module):\n",
        "    \"\"\"\n",
        "    Required Block Pattern: Conv(3x3) -> BatchNorm2d -> ReLU\n",
        "\n",
        "    Architecture:\n",
        "    1) Conv(1->16, 3x3, padding=1) -> BN -> ReLU\n",
        "    2) Conv(16->32, 3x3, padding=1) -> BN -> ReLU -> MaxPool(2x2)\n",
        "    3) Conv(32->64, 3x3, padding=1) -> BN -> ReLU -> MaxPool(2x2)\n",
        "    4) Flatten -> Linear(64*7*7 -> 10)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1, bias=True)\n",
        "        self.bn3   = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc    = nn.Linear(64 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)      # BN before ReLU (required)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)     # 28x28 -> 14x14\n",
        "\n",
        "        # Block 3\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)     # 14x14 -> 7x7\n",
        "\n",
        "        # Flatten + Linear\n",
        "        x = x.view(x.size(0), -1)  # (B, 64*7*7)\n",
        "        logits = self.fc(x)        # (B, 10)\n",
        "        return logits\n",
        "\n",
        "# -----------------------\n",
        "# 4) Device + Loss + Optimizer\n",
        "# -----------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"[INFO] device:\", device)\n",
        "\n",
        "model = CNN_Base_BN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 5\n",
        "print(f\"[INFO] Optimizer=Adam | lr=1e-3 | epochs={EPOCHS}\")\n",
        "\n",
        "def accuracy_from_logits(logits, y):\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "# -----------------------\n",
        "# 5) Train + Eval Loop (BN train/eval required)\n",
        "# -----------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    start_t = time.time()\n",
        "\n",
        "    # ---- TRAIN: uses batch statistics + updates running stats ----\n",
        "    model.train()\n",
        "    train_loss_sum, train_acc_sum, n_batches = 0.0, 0.0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "        train_acc_sum += accuracy_from_logits(logits, y)\n",
        "        n_batches += 1\n",
        "\n",
        "    avg_train_loss = train_loss_sum / n_batches\n",
        "    avg_train_acc  = train_acc_sum / n_batches\n",
        "\n",
        "    # ---- EVAL: uses running mean/var (no updates) ----\n",
        "    model.eval()\n",
        "    test_acc_sum, test_batches = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            test_acc_sum += accuracy_from_logits(logits, y)\n",
        "            test_batches += 1\n",
        "\n",
        "    avg_test_acc = test_acc_sum / test_batches\n",
        "    epoch_time = time.time() - start_t\n",
        "\n",
        "    print(f\"[EPOCH {epoch}] train_loss={avg_train_loss:.4f} | \"\n",
        "          f\"train_acc={avg_train_acc*100:.2f}% | \"\n",
        "          f\"test_acc={avg_test_acc*100:.2f}% | \"\n",
        "          f\"time={epoch_time:.2f}s\")\n",
        "\n",
        "# Optional: print final best accuracy estimate from last epoch\n",
        "print(f\"[RESULT] Final test accuracy after {EPOCHS} epochs: {avg_test_acc*100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}